{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(30000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 30 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 30\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/huawei123/kwx1991442/code-classification\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import *\n",
    "\n",
    "from torch import Generator\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "from src.baseline.dataloader import UITestsDataset\n",
    "from src.word2vec.dataloader import W2VClassificationCollator, TrainW2VModel\n",
    "from src.params import PATH_TEST_UI, PATH_PARSED_CLASSIFUI\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.main import parse_args\n",
    "\n",
    "args = parse_args(True, [\"--method\", \"word2vec\", \"--tokens-source\", \"origin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=4, classifier='bayes', device='cuda', exp_name='TEST', learning_rate=5e-05, liblinear_params='-s 5', max_seq_len=512, method='word2vec', mode='eval', n_epochs=8, save_all=False, save_metrics=False, save_model=False, save_predictions=False, seed=42, tokens_source='origin', traintestsplit=0.7, verbose=False, w2v_concat_method='mean', w2v_epochs=50, w2v_min_count=5, w2v_vector_size=500, w2v_window=500)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UITestsDataset is initialized in mode train from data/rust/tests/ui  with tokens_source='origin'. len(dataset)=233\n"
     ]
    }
   ],
   "source": [
    "if args.mode != 'eval':\n",
    "    raise NotImplementedError()\n",
    "\n",
    "# load data\n",
    "mode = 'train'\n",
    "tokens_source = args.tokens_source\n",
    "debug = True  # NOTE!!!!!!!!!!!!!!!!!!!!!!!!!WE ARE IN DEBUG MODE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "if tokens_source == 'origin':\n",
    "    tests_ui_folder=PATH_TEST_UI\n",
    "elif tokens_source == 'classifui':\n",
    "    tests_ui_folder=PATH_PARSED_CLASSIFUI\n",
    "\n",
    "dataset = UITestsDataset(tests_ui_folder, mode, debug)\n",
    "print(f\"UITestsDataset is initialized in mode {mode} from {tests_ui_folder} \"\n",
    "            f\" with {tokens_source=}. {len(dataset)=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split generator initialized with seed=42, lengths=[0.7, 0.30000000000000004].\n"
     ]
    }
   ],
   "source": [
    "# split data\n",
    "seed = args.seed\n",
    "traintestsplit = args.traintestsplit\n",
    "lengths = [traintestsplit, 1-traintestsplit]\n",
    "\n",
    "splitgenerator = Generator().manual_seed(seed)\n",
    "train_set, val_set = random_split(dataset, \n",
    "    lengths=lengths, generator=splitgenerator)\n",
    "print(f\"Split generator initialized with {seed=}, {lengths=}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaders are initialized with batch_size=1\n",
      "len(dataset.classes)=5, len(X_train)=164, len(X_val)=69\n"
     ]
    }
   ],
   "source": [
    "concat_method = args.w2v_concat_method #  TODO (NotImplemented)\n",
    "min_count = args.w2v_min_count\n",
    "vector_size = args.w2v_vector_size\n",
    "window = args.w2v_window\n",
    "epochs = args.w2v_epochs\n",
    "\n",
    "splitter, w2v_model = TrainW2VModel(train_set, tokens_source, min_count, vector_size, window, epochs).get_model()\n",
    "collate_fn = W2VClassificationCollator(w2v_model, splitter, dataset.classes)\n",
    "\n",
    "X_train, Y_train = collate_fn(train_set)\n",
    "X_val,   Y_val   = collate_fn(val_set)\n",
    "\n",
    "print(f\"{len(dataset.classes)=}, {len(X_train)=}, {len(X_val)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = collate_fn(train_set)\n",
    "X_val,   Y_val   = collate_fn(val_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X, Y = collate_fn(dataset)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, train_size=0.7, shuffle=True, random_state=args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_labels(Y_train, Y_val):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder().fit(Y_train)\n",
    "    Y_train = le.fit_transform(Y_train)\n",
    "    Y_val = le.fit_transform(Y_val)\n",
    "    return Y_train, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "\n",
    "# gnb = GaussianNB()\n",
    "gnb = BernoulliNB()\n",
    "gnb.fit(X_train, Y_train)\n",
    "Y_pred = gnb.predict(X_val)\n",
    "Y_prob = gnb.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'accuracy': 0.9130434782608695,\n",
       "  'micro_precision': 0.9130434782608695,\n",
       "  'micro_recall': 0.9130434782608695,\n",
       "  'micro_fbeta_score': 0.9130434782608695,\n",
       "  'macro_precision': 0.9130434782608695,\n",
       "  'macro_recall': 0.9130434782608695,\n",
       "  'macro_fbeta_score': 0.9130434782608695},\n",
       " {'precision': array([1.        , 1.        , 1.        , 1.        , 0.91304348]),\n",
       "  'recall': array([0., 0., 1., 0., 1.]),\n",
       "  'fbeta_score': array([0.        , 0.        , 1.        , 0.        , 0.95454545])},\n",
       " {'counts_y_val': array([ 1,  4,  1, 63]),\n",
       "  'counts_y_pred_x': array([4]),\n",
       "  'counts_y_pred': array([69])})"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "def evaluate(y_val, y_pred, labelencoder) -> Tuple[Dict, Dict, Dict]:\n",
    "    labels = labelencoder.classes_\n",
    "    encoded_labels = np.arange(len(labels))\n",
    "\n",
    "    m_vals, m_arrs, m_count = {}, {}, {}\n",
    "    m_vals['accuracy'] = accuracy_score(y_val, y_pred)\n",
    "\n",
    "    m_arrs['precision'], m_arrs['recall'], m_arrs['fbeta_score'], _ = precision_recall_fscore_support(\n",
    "        y_val, y_pred, average=None, zero_division=1., labels=encoded_labels)\n",
    "\n",
    "    _, m_count['counts_y_val'] = np.unique(y_val,  return_counts=True)\n",
    "    m_count['counts_y_pred_x'], m_count['counts_y_pred'] = np.unique(y_pred, return_counts=True)\n",
    "\n",
    "    m_vals['micro_precision'], m_vals['micro_recall'], m_vals['micro_fbeta_score'], _ = precision_recall_fscore_support(\n",
    "        y_val, y_pred, average='micro', zero_division=1., labels=encoded_labels)\n",
    "    m_vals['macro_precision'], m_vals['macro_recall'], m_vals['macro_fbeta_score'], _ = precision_recall_fscore_support(\n",
    "        y_val, y_pred, average='micro', zero_division=0., labels=encoded_labels)\n",
    "    return m_vals, m_arrs, m_count\n",
    "\n",
    "metrics = evaluate(Y_val, Y_pred, collate_fn.labelencoder)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.word2vec.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huawei123/kwx1991442/venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/home/huawei123/kwx1991442/venv/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "10 fits failed out of a total of 20.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/huawei123/kwx1991442/venv/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/huawei123/kwx1991442/venv/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/huawei123/kwx1991442/venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/huawei123/kwx1991442/venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/huawei123/kwx1991442/venv/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/huawei123/kwx1991442/venv/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/home/huawei123/kwx1991442/venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/huawei123/kwx1991442/venv/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/huawei123/kwx1991442/venv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan 0.82329545        nan 0.95738636]\n",
      "  warnings.warn(\n",
      "/home/huawei123/kwx1991442/venv/lib/python3.8/site-packages/sklearn/model_selection/_split.py:725: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for name in ['logreg', 'forest']: #, 'bayes_bernoulli', 'bayes_gaussian', 'liblinear']:\n",
    "    tr = Trainer(name, experiment_name='test', labelencoder=collate_fn.labelencoder)\n",
    "    tr.fit(X_train, Y_train)\n",
    "    m = tr.eval(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40f0bfdc1912eb71bf0d0b3c4b481e172567f32ca306c238f59a320dba5d47a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
