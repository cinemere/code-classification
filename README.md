[python-tokenize-library](https://docs.python.org/3/library/tokenize.html#tokenize.generate_tokens)

```
.
├── config.json
├── data
│   ├── classifui
│   ├── codeparrot-small
│   ├── GPT2-News-Classifier
│   ├── monkey-rust
│   ├── rust
│   └── sandbox
├── main.py
├── notebooks
│   ├── baseline.ipynb
│   ├── Prepare_data.ipynb
│   └── test.ipynb
├── parser
│   ├── Cargo.lock
│   ├── Cargo.toml
│   ├── model.json
│   ├── parsed_data                                                    # parsed data with in `classifui` style
│   ├── parsed_data_generalized                                        # parsed data with in `classifui` style (with generalization)
│   ├── src                                                            # parsing script
│   └── target
├── README.md
├── requirements.txt
└── src
    ├── dataloader.py
    └── __pycache__

15 directories, 11 files
```